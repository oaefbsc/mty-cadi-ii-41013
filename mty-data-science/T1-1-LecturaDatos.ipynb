{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de datos se hace a través de la función `read_csv()` contenida en el paquete **pandas** o bien por medio de la función `open()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos a través de read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirección absoluta del archivo titanic3.cvs\n",
    "data = pd.read_csv(\"data/titanic3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos parámetros de la función **read_csv()** son:\n",
    "- ruta del archivo:\n",
    "`filepath = \"/home/oscar/Documentos/udemy/machine-learning-joanby/python-ml-course-master/datasets/titanic/titanic3.csv\"`\n",
    "- separador:\n",
    "`sep = \",\"`\n",
    "- tipo de dato de una o mas columnas (campos):\n",
    "`dtype = {\"ingresos\":np.float64m \"edad\":np.int32}`\n",
    "- cargar el nombre de los columnas:\n",
    "`header = 0`\n",
    "- asignación de nombre a los columnas:\n",
    "`names = {\"ingresos\", \"edad\"}`\n",
    "- salto de registros e inicio de lectura:\n",
    "`skiprows = 12`\n",
    "- asignación de algún campo como índice:\n",
    "`index_col = None`\n",
    "- salto de lineas en blanco:\n",
    "`skip_blank_lines = False`\n",
    "- filtrado de datos sin valor:\n",
    "`na_filter = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga el archivo usando el paquete os para hace ruta absoluta + nombre del archivo \n",
    "mainpath = \"/home/oscar/Escritorio/misnotebooks/data/\"\n",
    "filename = \"titanic3.csv\"\n",
    "fullpath = os.path.join(mainpath, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lee un archivo .txt con separador \",\"\n",
    "data2 = pd.read_csv(mainpath + \"Customer Churn Model.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ocasiones cargan archivos en los que por un lado se tienen los datos y por otra parte se tienen las etiquetas de las columnas. En este caso se puede crear un dataset completo combinando los datos y etiquetas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lee un archivo con nombre de columnas\n",
    "data_cols = pd.read_csv(mainpath + \"Customer Churn Columns.csv\")\n",
    "# coloca los nombres de columnas en una lista\n",
    "data_col_list = data_cols[\"Column_Names\"].tolist()\n",
    "data_col_list\n",
    "# lee el archivo sin el nombre de las columnas asignando los nombres contenidos en la lista\n",
    "data2 = pd.read_csv(mainpath + \"Customer Churn Model.txt\",\n",
    "                    header = None, names = data_col_list )  \n",
    "data2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos a través de la función open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al cargar un archivo de datos con el paquete pandas, la función `read_csv()` carga todo el archivo en memoria. Para evitar saturar la memoria se puede utilizar la funcion `open()` de Python y leer linea por línea el archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga un archivo en modo lectura\n",
    "data3 = open(mainpath + \"Customer Churn Model.txt\", \"r\")\n",
    "data3 = open(mainpath + \"Customer Churn Model.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lee la primera línea y crea una lista \n",
    "# strip() elimina blancos y retorno de carro (\\n) de la línea\n",
    "# split() separa elementos de la línea usando \",\" como separador \n",
    "cols = data3.readline().strip().split(\",\")\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = len(cols)\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea un diccionario con clave nombre de columna\n",
    "# y valor una lista vacía \n",
    "counter = 0\n",
    "main_dict = {}\n",
    "for col in cols:\n",
    "    main_dict[col] = []\n",
    "main_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para cada línea del archivo\n",
    "for line in data3:\n",
    "    # quita blancos y separa elementos usando \",\"  \n",
    "    values = line.strip().split(\",\")\n",
    "    # inserta en el diccionario cada elemento de la lista values\n",
    "    # en la lista valor correspondiente\n",
    "    for i in range(len(cols)):\n",
    "        main_dict[cols[i]].append(values[i])\n",
    "    counter += 1\n",
    "    \n",
    "print(\"El dataset tiene %d filas y %d columnas\"%(counter, n_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(main_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer y escribir archivos con python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas veces los datos dentro de los archivos tienen como separador el tabulador: `\\t`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = mainpath + \"Customer Churn Model.txt\"\n",
    "outfile = mainpath + \"Test Customer Churn Model.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(infile, \"r\") as infile1:\n",
    "    with open(outfile, \"w\") as outfile1:\n",
    "        for line in infile1:\n",
    "            fields = line.strip().split(\",\")\n",
    "            # en el archivo de salida se escribe cada\n",
    "            # elemento de la lista fields unido\n",
    "            # con el caracter \"/t\" \n",
    "            outfile1.write(\"\\t\".join(fields))\n",
    "            # agrega una salto de linea \"\\n\"\n",
    "            outfile1.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(outfile, sep = \"\\t\")\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer desde una URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchas veces es necesario leer datos desde un localizador uniforme de recursos (URL: Uniform Resource Locator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos los datos contenidos en el archivo http://winterolympicsmedals.com/medals.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medals_url = \"http://winterolympicsmedals.com/medals.csv\"\n",
    "medals_data = pd.read_csv (medals_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medals_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paquete `urllib3` es un cliente http para Python3 que permite conectarse a una url. Ver también `urllib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "http = urllib3.PoolManager()\n",
    "# request() devuelve un objeto HTTPResponse\n",
    "response = http.request('GET', medals_url)\n",
    "# El objeto HTTPResponse provee los atributos status, data y header:\n",
    "response.status\n",
    "response.data\n",
    "response.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.data devuelve un objeto bytes que contiene\n",
    "# un flujo binario con los datos de la url\n",
    "responsedata = response.data\n",
    "type(responsedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decodifica el objeto bytes a utf8\n",
    "data_medals = responsedata.decode(\"utf8\")\n",
    "type(data_medals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = data_medals.split(\"\\n\")\n",
    "outfile = mainpath + \"Test Olympic Medals.txt\"\n",
    "with open(outfile, \"w\") as outfile1:\n",
    "    for line in lines:\n",
    "        outfile1.write(line)\n",
    "        outfile1.write(\"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_medals = pd.read_csv(outfile)\n",
    "olympic_medals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivos XLS y XLSX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los formatos de archivo .xls y .xlsx son formatos de hojas de cálculo de excel. El paquete pandas puede leer estos formatos con la función `read_excel()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mainpath = \"/home/oscar/Documentos/udemy/machine-learning-joanby/python-ml-course-master/datasets\"\n",
    "#filename = \"titanic/titanic3.xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el segundo parámetro de la función read_excel es el nombre de la hoja contenida\n",
    "# en el libro de excel\n",
    "titanic2 = pd.read_excel(mainpath + \"/\" + filename, \"titanic3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"titanic3.xls\"\n",
    "titanic3 = pd.read_excel(mainpath + \"/\" + filename, \"titanic3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones `to_csv(), to_json()` convierte un dataframe a un archivo del tipo especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic3.to_csv(mainpath + \"titanic3_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic3.to_json(mainpath + \"titanic3_test.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
